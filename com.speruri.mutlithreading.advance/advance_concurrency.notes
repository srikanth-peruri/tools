Advance JAVA
	You need to learn the basic java concurrency to understand the advance concurrency
	
	
1. Introduction to Executor Pattern, Futures and Callable 	
Usually we use Runnable pattern to create a thread.
Thread performs some task
	Never create a thread on ur own.
	Creating a thread is an expensive on
	So creating and terminating the threads are cumbersome and you should not do it especially in JAVA EE applications

How can we improve the performance of thread creation
	Instead for creating a threads with a task as a parameter on our own, we create pools of ready to use threads and then use from the pool.
	We pass a task to a pool of threads and that will execute it.
	
	We need two patterns
		The first one is to create a pool of threads
		pass the tasks (Runnables) to this pool to get executed

In java, pool of threads is an instance of Executor Interface
	Executor have only one method 	

We have another interface that extends the Executor
	ExecutorService extends Executor
		This has about 11 more methods. but we don't use everything

To create a thread pool we use the Executors factory class to create the pool.
	ExecutorService executorService = Executors.newSingleThreadExecutor();
	This create a pool with single thread.
	The thread will be in alive until the pool is alive
	calling executorService.shutdown() will terminate all the threads and pool as well.
	
There are 2 Executor Services can be used frequently.
	ExecutorService executorService = Executors.newSingleThreadExecutor();
		Creates a thread pool with one thread in it
	ExecutorService newFixedThreadPool = Executors.newFixedThreadPool(n);
		Creates a thread pool with 'n' no of threads.
	
	We then create the a runnable task and then pass it to the executor service
		Runnable task = () -> {System.out.println("Hi")};
		executorService.execute(task);
			this will start executing the task.
			
Suppose we created a executorService using single thread
	ExecutorService executorService = Executors.newSingleThreadExecutor();	
	And when we submit two tasks to this executorService with one thread, like
		executorService.execute(task1);
		executorService.execute(task2);
	Then the tasks would run in sequence. Since its a single thread executorService, the task2 should wait until the task1 is completed. 
	executorService internally contains a waiting queue in which the tasks will be held if there is no threads available. 
	The tasks are executed in order.

Questions
	Can we know from executorService whether the tasks are completed or not. 
		No, we have no methods to check that
	Can we cancel the execution at any time?
		No, if the execution started, yes if not started

ExecutorService wrapup			
	Its very efficient to create executorService instead of we creating the threads on demand. 
	It internally have waiting queue into which the tasks can wait until there is a thread available to perform its task
	The thread can execute any runnable passed.
	A task can be removed from the executorService if its not started yet.	
	
Limitations of Runnable.
	No exceptions raised. No lower level exceptions are transmitted ot the upper level
	No data is returned
	There is no way to know whether the task is done or not.
	This runnable task cannot produce a result.
	
	So, 
		how can a task return the value
		We need a new model to return a value and also transfer the exception to the upper layer
		Also, it should throw exceptions
		We also need an object that acts as a bridge between the threads
		Here is the new interface CALLABLE
		
CALLABLE
	its a functional interface
	It returns value as well as exceptions
	Here is that method
	
	@FunctionalInterface
	public interface Callable<v>{
		v call() throws Exception	
	}

	Executor doesn't handle this Callables since it only handles the Runnables.
	ExecutorService has a method submit(callables) which execute the callables and returns the Future
		
	Future<V> executorService.submit(callable<V> task);	

	When we submit the task to the executorService from main thread, then the executorService allocates a thread to this task
	When the executorService had some response for that task, then it returns the results with a FUTURE object to the main thread.
	Calling the future.get() returns the desired object
	Note that the get method is blocking method untill we get the result back from the executorService.
	
	Future.get might throw 2 exceptions
		1. Interrupted exceptions
			When u call the executorService shutdown.
		2. ExecutionException 
			when running the task

	If the task is completed and the result is available, the it immediately returns the results
	If not completed, then it blocks until the task is completed and then returns the result.
	We can also pass the timeout to avoid the blocking infinitely 


We have many executorService implementations in Java. But we use mostly 3
	1. ExecutorService executorService = Executors.newSingleThreadExecutor();
	2. ExecutorService newFixedThreadPool = Executors.newFixedThreadPool(8);
	3. ExecutorService executorService = Executors.newCachedThreadPool();	
	4. ScheduledExecutorService newScheduledThreadPool = Executors.newScheduledThreadPool(8);
	
	ExecutorService executorService = Executors.newCachedThreadPool();
		This is a lazy one and creates te threads on demand.
		Keeps the threads in pool for 60 secs and then terminates them
		
	ScheduledExecutorService newScheduledThreadPool = Executors.newScheduledThreadPool(8);
		Creates a schedules executor service with a pool
		we schedule a task in the future
		we can execute the tasks with fixed delay till some period of time	
		
There are 3 ways to shutdown the executorService 
	1. executorService.shutdown()
		waits for the submitted tasks to be completed 
		executes waiting tasks
		donot accepts the new tasks
		then shutdown
		
	2. executorService.shutdownnow()
		halts every running tasks and waiting tasks and then shutsdown
		it throws the ExecutionExceptions and then quits
		not accepts the new tasks
		
	3. awaitTermination(millis)
		terminates the running tasks after the timeout
	
2. Using locks , semaphores for Producer/Consumer pattern

Intrinsic Locking
	synchronization or volatile are the intrinsic locks.
	It is nothing but the synchronization where we will have a Object as a lock in the class like.
	private final Object key = new Object();
		Only one thread will be allowed to get the key and then execute the synchronization block of code
		When the thread inside the synchronization block is blocked, then all the other threads waiting to get the access will also be blocked
		There is no way in jave to unblock it and we should restart the JVM
		
	Instead of writing such above code, we can use another process of LOCK pattern
LOCK
	Lock is the java object which acts same as the synchronization block.
		It provides the same exclusion, read and write ordering
		Happens before link.etc
		This is explicit locking using Lock interface
	
	Lock is an interface and ReentrantLock is the implementation
		
		Lock lock = new ReentrantLock();
		try{
			lock.lock().
			//Do something here
		}catch(Exception e){
			//catch exception
		} finally {
			lock.unlock();
		}
		
	Lock is having more features 
		Instead of passing instance of an object as lock 
		To guard several blocks of code
		We create a lock object
		we have several methods in the Lock object

Mainly there are 3 types of Lock patterns
	Interruptible Lock Acquisition
	Timed Lock Acquisition
	Fair Lock Acquisition
	

Interruptible Lock Acquisition
	using lock.lockinterruptible
		This is interuptible pattern
		The thread will wait until it can enter the guarded block of code
		Another thread can call interupt on it so that the running thread can interrupt
		This not possible with synchronization pattern
		
Timed lock acquisition
	This is a timed lock acquisition
	When a thread is running the code inside the block, then calling the tryLock will return false 
	It also takes timeout parameter 
	
		lock.tryLock()

Fair Lock Acquisition
	When mutliple threads tried to execute a block on synchronized block of code, then the thread is choosen randomly. When we declare the folowing
			Lock lock = new ReentrantLock(true);
	Then it becomes the fair lock
	This is very costly and need to be careful while implementing this.
	then the thread which comes in the first place will be given the key to enter the block of code
	
			
Condition
	Condition is an object from lock.
	Lock generates the condition and it has await and signal methods similar to wait and notify
	Condition also extends the Object class and we shouldnot call wait() and notify() of Condition since they won't work because we are not in the 
		synchronization block
	
	The await() call is blocking and can be interruptible
	There are 5 methods for await method
		await()
		await(millis, timeunit)
		awaitNanos(nanotimeunits)
		awaitUntil(date)
		awaitUninterruptibly()
		
ReadWriteLock 
	ReadWriteLock is an interface with two method
		readLock()
			return read Lock object
		writeLock()
			returns write Lock object
	
	
	Rules are
		Only one thread can hold the Write Lock
		When Write lock is held, then no one should hold read Lock
		As many thread can hold the read lock when no write lock is held
	
	This can be created as
		ReadWriteLock readWriteLock = new ReentrantReadWriteLock();
		Lock readLock = readWriteLock.readLock();
		Lock writeLock = readWriteLock.writeLock();
		
	Wrap up
		ReadWriteLock gives readlock and writelock. 
		When getting the pair, we should get it from the same ReadWriteLock 
		Useful in implementing the caches

Semaphores
	Came from the unix OS
	Its a kind of lock, but it allows multiple threads to execute a block of code
			
	Semaphore semaphore = new Semaphore(5);
	
	semaphore.acquire()
	semaphore.release()


3 Controlling concurrent applications using Barriers and Latches

Barrier
	To have several tasks to wait for each other 
	Suppose if we want to do heay computation, then we can provide each thread with a task.
	Once all the threads are done with their processing, then we can merge operation to be run
	We need some subsequent task to merge them
	This is called barrier
	
	Assume that we need to compute the prime numbers till some certain number, then we can leverage the CPU cores for doing this
	with multiple threads. Say for example, if the i7 CPU has 4 cores, then we can make use of 4 threads to compute and find the 
	prime numbers

	Finally we can merge all the sets to get the final super set	
	
	We can leverage the Cyclic Barrier for this task
	
	We can create a Cyclic Barrier with no of tasks passed to it as Runnables.
		When each runnable done performing its tasks, then it calls the barrier.await()
		Cyclic barrier counts the await() calls from all the threads. If the count is equal to the no of tasks generated on this barrier, then
		it provides all the results back and we can also provide the callback function to perform post processing tasks. 
	
	Barrier also throws exception. It has 2 await methods
		await() - waits indefinetely
		await(millis, timeunit) - waits for the passed amount of time.
	
	Cyclic barrier is a 
		tool which synzronize several threads between them and let them continue when they are reach common point
		Its closed when created and will be opened when the threads having this barrier reaches a common point.
		It can also reset
	
	
Latches
	Latches are similar to the Barriers exceppt one difference
		Suppose we have an application which depends on many services like
			Authentication Service, Data service, Order service..etc
		In such case, if we use Barrier, it would be fine but, we should not make the barrier reset. Thus blocks everything and we might have an impresions that some services are not started properly 
	 	we need a Barrier which can be opened but cannot be closed.
		So this can be achieved with Countdown Latch
	
	Suppose the we have 4 tasks which was have the same Latch are executed, then it acts similar to the Barrier but the only thing is that it wont be reset or closed.
	
		 
	
4. Understanding CASing and Atomic Variables

CASing
	CASing is Compare and swap
	Its an OS related topic
	Its a set of Assembly instructions and low level functionalities
	CASing works with 3 parameters
		1. location in the memory
		2. Existing value at that location
		3. New value to be written at that location
		
	If the current value at that address is the value we expect, then we just update the value and return true. Or else return false since there is some update happened at that location.
	All this happens in a single atomic assembly instruction
	
	AtomicLong is one of the example.
		AtomicLong is a wrapper on top of the Long and used to incrementing the counters
		It helps to increment the counter without the use of synchronization in case of multiple threads accessing it for read/write.
		It uses CASing technique to do that
		When java tries to increment the counter, then CASing tells the calling code that increment fialed if another thread had changed the value in the meantime.
		if the increment is not success, then the API tries until it gets incremented.
		 
	AtomicBoolean
		It has the following methods
			get(),set()
			getAndSet()
			compareAndSet(expected, value)
	
	AtomicInteger
		get(),set()
		getAndSet()
		compareAndSet(expected, value)
		getAndUpdate(uniaryOperator)						
		updateAndGet(uniaryOperator)
			uniary operator is just the operation on the existing value
	
	AtomicReference<V>
		This is a Wrapper on the object reference
				
	
	Casing works well when concurrency is not too high
	If Concurrency is too high, then the update operation on memory by many threads will lead to retries and might overload the CPU/memory
	Since only one thread wins and all the other threads are trying and trying to win.
	
	In case of synchronization, only one thread enters the block of synchronization code and other threads wait. 
	But where as in case CASing, every thread tries to access the code but only one wins. the other failing thread will continously tries to update the variable.
	 
	So, Atomic Variables are the tools to handle Concurrent read/writes using CASing technique
	It is different from synchronization 
	It should be used with are. And not to be used with high concurrent threads
	
Adders and Accumulators
	These are added in java 8
	In case of CASing, all the methods are dependant on 
		'get and modify' or
		'modify and get'
	In some cases, we no need the 'get' call and could save time for us. This is where we use Adders/Accumulators
	There are LongAdder, LongAccumulator are used for this purpose, they won't return the value after modification
	
	It acts similar to the AtomicLong but didn't return the value. 	








	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
		
	