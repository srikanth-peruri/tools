Java memory course helps in knowing the java memory
	This course will let us know the java memory leaks
	Java memory management..etc
	And then how to deal with the memory issues in java during production issues


Java doeas have a Garbage Collector (GC) which cleans up the unused resources 
	but they are just computer programs itself
	They only can free when the objects are not in use or reffered by any other object
	But the developer only know where he needs the resources to be cleaned up
	
Java MEmory issues are been debugged mainly in two methodologies
	1. Headless Chicken Manner
		Very Popular - almost all the engineers follow the same pattern
		Compares the present situation with the past experience using assumptions
		Panic Driven
		Stare at lot of code
		Guesses at what went wrong
		
		
	2. Scientific Approach 
		But there are smart people which are rare 
		Follows repeatable solutions
		Measures a part of the program
		Alter code to fix the problem
		Re-measures to ensure that nothing has been broken
		
The course outlines the following topics
	1. Building your memory analysis toolkit
	2. Knowing/Fixing the memory leak issues
	3. Fixing Advanced memory leak issues
	4. Solving Out Of memory issues
	5. Understand the Object allocation rate problems
	
	
1. Building Memory Analysis Toolkit
	Java comes with some pre-installed out of the box tool to inspect the memory, heap dump, memory profiling
		First we will know about the 
	A. Inspecting the VM		
		a. JPS
			Used to profile the Java memory
			Ships with hot spot JVM's like Oracle JDK, Open JDK, Sun JDK
			Its a command line tool					
		b. JVisualVM
			Its a GUI tool to scan the java memory and processes similar to jps
		
	B. Object Histogram
			Object histogram is the visual representation of how the objects are allocated with memory.
				they tell us what is there currenlty in memory, but cannot tell the past memory state
				Very quickly to collect the histogram
				Low details of an object but not the relation ships between these object and what part of the code is referring these objects
			Tools like jmap
				jmap --histo:{live,] pid
					This command will show all the objects on that process ID
					This also shows how many instances are in use and how much are they occupied
					Sometimes we see [B, [I, IC these are arrays of Bytes, Integers, Chars respectively
					java.lang.String is a normal object
					[Ljava.lang.Object represents the array of objects. L represents the object of a Type
					The primitives like char, int, long are on the stack space of the object but on the HEap
					Heap only holds the Objects 
	
	B. Getting the Heap Dump
		A copy of all the live objects in the applications heap
		Heap dump is the current state of the JVM.
		It tells about what objects are there in memory and how much it occupied
		Also tells about the detailed info about the object relationships
		Its large in size and very slow when compared to Object Histogram since object histogram shows only the amount of memory occupied by each object but not the relationships between objects
		1. jmap -dump:file = filepathtodump pid
			This dumps the current state of the JVM to the file for that java process ID
			Heap dump tell us the info about the current state of the VM and can helpful in debugging the cause of the OutOfMemory issues
		2. The other way to get the HEapDump in the production environment is
			-XX:HeapDumpOnOutOfMemoryError
			-XX:HeadDumpPath=/path/to/dump
			If the user performs too much GC, then there would be a chance of getting this OutOfMemoryError
			
			But there is some downsides of this as well in case of Large heap sizes. It takes ages to to heap all the memory into a file.
			This could be gigs of data and this could make the restart of the application delay
			
			To Analyse this hprof file, we need the analyser tools like Eclipse MAT, JVisualVM, jhat (deprecated) ..etc
			eclipse mat is very efficient to analyse the heap dump

	C. Java Memory Profiling
		It profiles the event driven actions
		Tells the patterns of the memory allocation activity
		records memory allocation and related info
			There are two tools for this memory profiling
				1. JVisualVM
					Free open source ships with Jdk
					includes a memory tool
					can disable the escape analysis
					
				2. Java Mission Control
					Free for use is development
					more accurate
					ships with java 8+
					included a memory profiler
			
	Module wrapup
		In this module, we came to know about how to
			Inspect the VM
			Object histogram
			Analyse/get the Heap dump
			Memory Profiling
					

2. Solving memory leaks
	What is a memory leak
		The memory that has been allocated to an object. And when the object is no no longer needed anymore and is not released, then a memory leak can happen.
		Even the GC cleans the unreferenced objects, we may still get the memory leak issues
		We can analyse the memory leaks with the above tools mentioned.
			The live objects which are refered will not be deleted by GC
			Only the objects which lost the refernce will get deleted. For example, the local variable in the function will get GC'ed when the control exits the function. But
				it may not happen at that point of time. GC puts tracks of the objects and deletes them in batches
		Memory leaks mostly happens with the instance variables of that class. This may be referred by some other objects and not released even these is no use.
		GC is a reliable technique but it will not prevent the application from Memory leaks	
		But the responsibility lies in the hands of the programmer by keeping things alive that are genuinely going to be used by the prpogram
		you are the one who should decide what object to live and what objects to be cleared
		It should act on the information you provide
	
	Solving memory leaks using Heap dumps
		Here is the leak finding process
			As we discussed earlier, we can use the heap dump to check what is causing the memory leak
			The object histogram says what object is taking more memory and these are the more noise creating objects 
			Here is the steps
				1. Get all the objects which are retained in the memory with the hprof file
					this will show us all the objects in the heap at that point of time and then creates a snapshot of the heap
				2. Go through the heap Object histogram and filter the objects which are occupying more memory
					filter the object histogram to see the noisy objects
				3. Look at what objects are referencing and the objects being referenced by
				
		Some of the memory leak issues
			When you are inserting the objects in to the hashmap, then remember to override both the hashcode and equals methods.
			If we only override the hashcode method, then we might get the memory leak issues
					 
	Memory Profiling
		We use memory profiling and find what is leaking memory
		GC will spins up for a while and releases the memory thats been used within the heap
		But when the GC performs the clean up, then some of the objects might cleared off in the first cycle itself (first cycle after that got generated), but
		some might have passed most of the GC cycles. This is called the generational cycles. The more the generational cycle count, the more chances are there for those 
		object to be a memory leak candidate. So, keep an eye on them.
		Whenever you develop a product, run these tests and see how the application is growing in size and see the patterns of how the applciation is behaving.
		
		
3. Advanced Memory Leaks issues
	There are 3 kinds of the Advanced memory leaks. They are
		a. Class loader memory leaks
		b. ThreadLocal memory leaks
		c. Off space memory leaks		
		
	a. Class Loader MEmory leak
		Class loaders are the one which loads the bytecode into the JVM for executing. 
		These byte code is the .class file which was generated by the javac compiler
		There are 3 default Class loaders 
			1. Bootstrap Class loader
			2. Extension Class loader
			3. System Class loader
		These are not the cause for the memory leak since they are default Class loaders shipped with jdk, but the issue comes when we have 
		a custom Class loader and when we donot unload the classes from JVM. This should be handled with very care or it could result in the 
		memory leaks
		For example, the loading of servlet container might have custom class loader for resources and all.
		
		When we have a custom Class loader which creates new classes, then it holds the reference to the classes generated.
		Also the classes generated will also have reference to that class loader. 
		So when we try to clear the Class loader reference, then it won;t get cleared since it holds the reference to the classes it generated 
		and when we try to clear the classes generated, then they wont get cleared since they hold the reference to the Class loader
		Class loader will also have reference to the static fields of these classes and also the byte code of the classes
		This leads to have dangling references and will never get cleaned up by GC.
		JVM loads the byte code into a memory space called Permgen in or < java8. And its called as Metaspace in case of java8 and above
		  
		Memory leaks can happen with the inner classes that hold references to the outer class instances.
		So while using the custom Class loader, we should be very careful
		
	b. Threadlocal variable
		Its a field, where every thread having its own independently initialized copy of variable.
		Thread local is a local variable to that particular thread and hold an initial value. IT only visible for that thread
		Normally in jave, every field is associated with something
			static field is associated to class
			instance variable is associated to the surrounding object
			Threadlocals are fields which give a 1 to 1 relationships between the instance copies and the threads itself
		
		These values will get cleared when they are finished with the  thread execution
		But, if you want to reuse the same thread for the other actions like servlet containers, then there is a big risk of having memory leaks
		
		We should clear the Threadlocal variable values after the usage
		
	c. Off Memory Leaks
		There are two types of memories on to which Java works on
			a. Heap Space
				This is where the Java objects are loaded
				Managed by JVM/GC
				Java objects are allocated here
				These are automatically garbage collected		
			b. Off Heap Space	
				Managed Manually
				individually allocated buffers
				Used for Custom data stores
				An application or some framework need to manage this memory manually
				Types of Off heap memory
					1. Native code like JNI uses JNI invoked libraries
					2. Direct Buffers- Off heap buffers allocated by java 
					3. Memory mapped files - used for inter process communications used to write to network or file systems
				The heap dumps can show only the heap state and not the off heap state.
				Byte buffers in java uses this memory mapping files for communicating with the file system and network
				
				We have a JVM argument which restricts the max usage of this off-heap memory 	
					-XX:MaxDirectMemorySize=1g
						This enforces the buffer allocation limit
						stops unbounded growth
						still needs to find leaks
							
					
				Java allocates the direct buffer for Bytebuffers. When we call 
				ByteBuffer.allocateDirect, then it allocates the memory in off heap memory and not on the heap 
				This way, when we get the heap dump, this will not show the off heap memory occupied by these byte buffers
				
		
4. Solving "OutOfMemory" errors
	This error happens when you are ran out of memory during the application runtime
	This might not happen in the Production env quite often. But its always good to know the issues ahead and fix them
	The main reasons for the OOM is that
		1. BEcause of the outOfMemory issues that cause because of the Memory leaks
		2. Your application might over consume lot of memory as the time grows. Like you are using too much memory to perform a task
		
	When starting the JVM we provide the -Xmx and -Xms values as arguments to the JVM
		-Xmx is the max heap to allocate to the JVM
		-Xms is the default minimum heap size to allocate when the application launches	
		If you dont pass these values, the -Xmx value is defaulted to the 1/4th's of the Systems memory.
		For example, you might have OOM when many concurrent users login at the same time
		The memory consumption might grow based on the transactions at that particular time but go down once you free up the memory after the transactions
		When you fail to clean up the resources, then there might be a OOM
		
	The application might have heavy load sometimes, but we can have some tatics to reduce the memory consumetion by following steps
		1. Identify whats using the memory
			To identify the cause of OOM ahead of time in development, allocate the lesser memory to the JVM using Xmx and then get the heap dump using JVM argument
			-XX:HeapDumpOnOutOfMemoryError
			This creates a hprof file when we get the OOM during application runtime
		2. Reduce Memory Consumetion
			Allocate less memory, don't refernce as much
			First tactic is to use the primitive types rather than Boxed types
				For example, using int which is 4bytes is far lesser that boxed type Integer (around 16-24 + 8 bytes for reference = around 32bytes)
				So using boxed types consume 32 bytes where as primitive uses 4bytes, there is a huge savings with this.
			
			Second tactic is caching the values
				Sometimes, caching might cause issues when we store and forget to consume/clean
				So, better use small collections, reuse/reassign them when you are done calculating them
			
			Third tactic to simplyfying the Domain model
				Avoid many abstraction layers
				Don't go with more complex model - every layer consumes memory
				Refactor whenever possible to remove the unnecessary layers of abstraction
				
			Fourth Tactic
				If the application needs to handle thousands of concurrent users, then better increase the heap size with more RAM
				pass the max value as argument
					-Xmx16G	
				Increase the RAM - Also becareful in increasing the RAM since, it might have more swapping which is very very slow.
				If we don't set the max heaosize, then JVM by default consumes the 1/4th of the system memory
				
			Fiveth Tactic
				Donot hold the reference to the object in memory which you don't need.		
				
		3. Measure again to validate
		
			
		Proactive measure to prevent OOM
			Prevention is better than cure
			The steps is to
				Memory Consumption monitoring
				Get GC logs and use jmap, JVisualVM for monitoring the applciation
				You can use Application monitoring tools like promethius, graphite, nagios ..etc to perform these monitoring.
				You can perform the stress/performance testing and get the numbers to publish of how many can concurrently use the system.
				

5. Understanding Object Allocation rate problems
	There could be two major issues with the time
		1. Latency/responsiveness of the application to the user requests
			Whem an user requests the server, then the time taken will be more for processing that request.
			
		2. Throughput/efficiency of the application
			The no of requests that were processed in an amount of time
			i.e, max no of requests per second.
		
		Here is the differnce between them
			Latency
				A request takes atmost Xms
				In practice the latency rises under load
				How fast to keep the users happy
				Y% of requests take at most Xms at Z requests/sec
			
			Throughput
				no of requsts per sec
				How many requests per sec to be processed at the peak time
				Any depreciation of these throughput might need some investigation. This is worth
				
		Reduce the allocation of objects for two reasons
		
			CPU cache locality
				Allocating objects reduces the effectiveness of your CPU's cache
				Allcoating more and more objects in memory will reduce the efficiency of the CPU cache. This could be because of Cache miss and refreshes the cache
				by getting the values from memory again (this was seen in the concurrent programming)
			Time spent allocating
				Actually allocating the objects takes time and its not free
				The more time you allocating the objects, the less time you spend in doing actual work
			
			There are two types of profilers
				Execution profilers
				
				Memory Profilers
				
		Usually GC works in the following way
			The objects allocated are arranged in young or older space
			GC performs more effectively on this younger space.
			The objects which are survived the generational counts, then they are promoted to the older space
			These older objects will take more time to get cleared. This can be cleaned only in case of FUll GC
			
			This could be one more reason for GC pauses
				 GC pauses will get triggered when there is more young objects are created
			There will a premature promotions to the old gen
			
			This leads to more frequent Full GC cycles and will slow down the application and also longer GC pauses
			
			
			
				
		
					
		
		
		 
		



	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	